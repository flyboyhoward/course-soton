{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fit A mat\n",
    "def designmatpoly(X, wtvector):\n",
    "    X = X[:,0]\n",
    "    A_traint = np.ones(X.shape)\n",
    "    #print (len(wtvector), np.shape(A_traint))    \n",
    "    \n",
    "    for i in range(len(wtvector)-1):\n",
    "        X_row = X**(i + 1)\n",
    "        A_traint = np.vstack((A_traint, X_row))         \n",
    "    A_train = A_traint.T\n",
    "    #print (np.shape(A_train))\n",
    "    return A_train\n",
    "\n",
    "# regularisation gradient descent function\n",
    "def reg_gradientdescent(w, X, y, l2, rate, n_iterations):\n",
    "    wtseq = [w]\n",
    "    for iteration in range(n_iterations):\n",
    "        #print('iteration is:', iteration)\n",
    "        gradients =  2/len(X) * X.T.dot(X.dot(w) - y) + 2 * l2 * w\n",
    "        #print ('gradients',gradients)\n",
    "        w = w - rate * gradients\n",
    "    print ('final gradient',gradients)\n",
    "    return w\n",
    "\n",
    "# squared residuals\n",
    "def squared_residual(x_test, y_test, wt):\n",
    "    residual = 0\n",
    "    x_test = x_test[:,0]\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        y_predi = 0\n",
    "        x_testi = x_test[i]\n",
    "        for wti in range(len(wt)):\n",
    "            y_predi += wt[wti]*np.power(x_testi, wti)\n",
    "        residual += (y_test[i] - y_predi)**2   \n",
    "    #print('residual is:************ ', residual)\n",
    "    return residual\n",
    "\n",
    "# predicted value\n",
    "def predict(x, wt):    \n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        y_predi = 0\n",
    "        x_i = x[i]\n",
    "        for wti in range(len(wt)):\n",
    "            y_predi += wt[wti]*np.power(x_i, wti)\n",
    "#             print(wt[wti]*np.power(x_i, wti))\n",
    "#             print('---------------------------------')\n",
    "#         print('*************')\n",
    "        y_pred.append(y_predi)\n",
    "#   print('y_pred shape',np.shape(y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "points = 180\n",
    "X = np.linspace(0, 2*np.pi,points)\n",
    "y = f(X)+np.random.normal(0,0.1,points)  # np.sqrt(np.abs(X))*\n",
    "X = np.atleast_2d(X).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "final gradient [ 0.49975404  0.33542492  0.04899882 -0.25115626  0.07746067 -0.00648703]\n",
      "residual is:  2.7582686701958608\n",
      "final gradient [ 0.5481237   0.34902298  0.05114239 -0.25754262  0.07882624 -0.00656309]\n",
      "residual is:  5.289843588492224\n",
      "final gradient [ 0.5645219   0.37163241  0.06664038 -0.26633876  0.07959297 -0.00653683]\n",
      "residual is:  5.074791510980437\n",
      "final gradient [ 0.54797179  0.36303671  0.0694211  -0.25864132  0.07673677 -0.00627868]\n",
      "residual is:  4.90233550206354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 10)\n",
    "kf.get_n_splits(X)\n",
    "wtseq = []\n",
    "residseq = []\n",
    "print(kf)  \n",
    "w0 = np.ones(6)  # polynomial degree\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    A_train = designmatpoly(X_train, w0)\n",
    "    wtfin = reg_gradientdescent(w0, A_train, y_train, 0.5, rate = 0.00000001, n_iterations = 40000000) # take lamda = 1 here\n",
    "    wtseq.append(wtfin)\n",
    "    resid = squared_residual(X_train, y_train, wtfin)\n",
    "    print('residual is: ', resid)\n",
    "    residseq.append(resid)\n",
    "    \n",
    "plt.scatter(X, y, c='b')\n",
    "\n",
    "\n",
    "wtseq = np.asarray(wtseq)\n",
    "resid_min = np.min(residseq)\n",
    "place = np.where(resid_min == np.min(residseq))\n",
    "wtbest = wtseq[place]\n",
    "print('wtbest is: ')\n",
    "ypred = predict(X, wtbest.T)\n",
    "# print('y predict is: ', ypred)\n",
    "plt.plot(X, ypred)\n",
    "print('best wt matix is: ',wtbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02567177],\n",
       "       [ 0.10889941],\n",
       "       [ 0.12557531],\n",
       "       [-0.09097697],\n",
       "       [ 0.01089173]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtbest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(wtbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.23280457,  0.56460444,  0.89715102, -0.60060176,  0.09485012,\n",
       "       -0.00388118])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtseq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(wtbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21324958,  0.1117614 ,  0.10002549,  0.04056122, -0.0362525 ,\n",
       "         0.00436364]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
